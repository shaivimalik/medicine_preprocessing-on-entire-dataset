::: {.cell .code}
```python
!git clone https://github.com/shaivimalik/medicine_preprocessing-on-entire-dataset.git
%cd medicine_preprocessing-on-entire-dataset
!pip install -r requirements.txt
!curl -O https://physionet.org/static/published-projects/tpehgdb/term-preterm-ehg-database-1.0.1.zip
!unzip term-preterm-ehg-database-1.0.1.zip
!mkdir individual_features
!python3 EHG-Oversampling/experiments/all_features.py term-preterm-ehg-database-1.0.1/tpehgdb individual_features --study FeaturesKhan
!python3 EHG-Oversampling/experiments/process_feature_files.py individual_features ./
%cd notebooks
```
:::

::: {.cell .code}
```python
import os
import imblearn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, make_scorer
```
:::

::: {.cell .code}
```python
#Loading feature vectors
features=pd.read_csv(os.path.join('..','raw_features.csv'))
features.head()
```
:::

::: {.cell .code}
```python
#Loading labels
y=pd.read_csv(os.path.join('..','target.csv'))
y.head()
```
:::

::: {.cell .code}
```python
# Extracting features required for our study
khan_features = [
    'FeaturesJager_fmed_ch1', 'FeaturesJager_max_lyap_ch1',
    'FeaturesJager_sampen_ch1', 'FeaturesJager_fmed_ch2',
    'FeaturesJager_max_lyap_ch2', 'FeaturesJager_sampen_ch2',
    'FeaturesJager_fmed_ch3', 'FeaturesJager_max_lyap_ch3',
    'FeaturesJager_sampen_ch3',
 ]
generic_features=[ c for c in features.columns if 'FeaturesAcharya' in c and 'SampleEntropy' in c ]

# Extract the relevant features for the study
X = features[khan_features + generic_features]

# Display summary information about the selected features
X.info()
```
:::

::: {.cell .code}
```python
# Define specificity and sensitivity scoring functions
def specificity_score(y_true, y_pred):
    return recall_score(y_true, y_pred, pos_label=0)
def sensitivity_score(y_true, y_pred):
    return recall_score(y_true, y_pred)

# Create scorers using make_scorer
specificity = make_scorer(specificity_score)
sensitivity = make_scorer(sensitivity_score)

# Define parameters for grid search
gamma_range = np.logspace(start=-5, stop=5, num=11, base=2)
C_range = np.logspace(start=-5, stop=5, num=11, base=10)
parameters_incor = {'C': C_range, 'gamma': gamma_range}

# Define scoring metrics for grid search including accuracy, sensitivity, and specificity
scoring = {'accuracy':'accuracy','sensitivity':sensitivity,'specificity':specificity}
```
:::

::: {.cell .code}
```python
# Define the pipeline
model = imblearn.pipeline.Pipeline([
        ('ADASYN', imblearn.over_sampling.ADASYN(random_state=5)),
        ('SVM', SVC(kernel='rbf', random_state=5))
    ])

# Define the parameters grid for GridSearchCV
parameters_cor={'SVM__C': C_range, 'SVM__gamma': gamma_range}

# Define GridSearchCV with custom scorers
clf_cor = GridSearchCV(model, parameters_cor, cv=10, scoring=scoring, refit='accuracy')

# Perform grid search
clf_cor.fit(X.to_numpy(), y.to_numpy())

# Print results
print("Accuracy:", clf_cor.best_score_)
print("Error:", (1-clf_cor.best_score_))
print("Sensitivity:", clf_cor.cv_results_['mean_test_sensitivity'][clf_cor.best_index_])
print("Specificity:", clf_cor.cv_results_['mean_test_specificity'][clf_cor.best_index_])
print("Best hyperparameters:", clf_cor.best_params_)
```
:::

::: {.cell .code}
```python
# Set the figure size
plt.figure(figsize=(10, 8))
# Reshape the mean test accuracy scores into a 2D array
scores = clf_cor.cv_results_["mean_test_accuracy"].reshape(len(C_range), len(gamma_range))
# Display the scores as a heatmap
plt.imshow(scores, interpolation="nearest", cmap=plt.cm.hot)
# Set the x-axis label
plt.xlabel("gamma")
# Set the y-axis label
plt.ylabel("C")
# Display the colorbar
plt.colorbar()
# Set the x-axis ticks and labels
plt.xticks(np.arange(gamma_range.shape[0]), labels=gamma_range, rotation=45)
# Set the y-axis ticks and labels
plt.yticks(np.arange(gamma_range.shape[0]), labels=C_range)
# Set the title of the plot
plt.title("Validation accuracy")
# Display the plot
plt.show()
```
:::