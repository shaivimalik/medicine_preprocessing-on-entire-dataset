{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “Characterization of Term and Preterm Deliveries using Electrohysterograms Signatures” Without Data Leakage\n",
    "\n",
    "[![Open In\n",
    "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shaivimalik/medicine_preprocessing-on-entire-dataset/blob/main/notebooks/Correcting_Original_Result.ipynb)"
   ],
   "id": "866963c1-7319-45b7-8175-ae290e4fc625"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the preceding notebooks, we demonstrated the impact of data leakage\n",
    "on a model’s performance on the test set and real-world data. In this\n",
    "notebook, we will reproduce the results published in **Characterization\n",
    "of Term and Preterm Deliveries using Electrohysterograms Signatures**[1]\n",
    "without the data leakage error. Our goal here is to demonstrate the\n",
    "correct way of preprocessing the dataset and discuss the changes in the\n",
    "reported metrics upon rectification of the error.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "-   Implement the described techniques and train SVM without data\n",
    "    leakage errors.\n",
    "-   Analyze and compare our results with those published in the paper\n",
    "    and obtained in the previous notebook.\n",
    "\n",
    "[1] M. U. Khan, S. Aziz, S. Ibraheem, A. Butt and H. Shahid,\n",
    "“Characterization of Term and Preterm Deliveries using\n",
    "Electrohysterograms Signatures,” 2019 IEEE 10th Annual Information\n",
    "Technology, Electronics and Mobile Communication Conference (IEMCON),\n",
    "Vancouver, BC, Canada, 2019, pp. 0899-0905, doi:\n",
    "10.1109/IEMCON.2019.893629"
   ],
   "id": "7c469c46-e7c1-4945-bb78-8fb5972400bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines if running on Google Colab\n",
    "#!git clone https://github.com/shaivimalik/medicine_preprocessing-on-entire-dataset.git\n",
    "#!pip install -r requirements.txt\n",
    "#%cd medicine_preprocessing-on-entire-dataset/notebooks"
   ],
   "id": "9c404a9c-5267-4d4c-a1c5-67359e0c248c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the data & Generate Features\n",
    "\n",
    "The **Term-Preterm EHG Database**[1] is a collection of EHG signals\n",
    "obtained from 1997 to 2005 at the University Medical Centre Ljubljana,\n",
    "Department of Obstetrics and Gynecology. Electrohysterograms signatures\n",
    "are obtained by placing four electrodes on the abdomen of the mother.\n",
    "The TPEGH DB consists of EHG records obtained from 262 women who had\n",
    "full-term pregnancies and 38 whose pregnancies ended prematurely. Each\n",
    "record is composed of three channels, recorded from 4 electrodes. The\n",
    "differences in the electrical potentials of the electrodes were\n",
    "recorded, producing 3 channels. Each record consists of two files, a\n",
    "header file (.hea) containing information regarding the record and the\n",
    "data file (.dat) containing signal data[2].\n",
    "\n",
    "We’ll begin by acquiring the TPEGH DB (Term-Preterm ElectroHysteroGram\n",
    "Database) and extracting relevant features for our model training. The\n",
    "following cell will:\n",
    "\n",
    "-   Clone the project repository\n",
    "-   Download the TPEGH DB dataset\n",
    "-   Install required dependencies\n",
    "\n",
    "Note that the download may take some time depending on your internet\n",
    "connection speed.\n",
    "\n",
    "[1] Fele-Žorž, G., Kavšek, G., Novak-Antolič, Ž. et al. A comparison of\n",
    "various linear and non-linear signal processing techniques to separate\n",
    "uterine EMG records of term and pre-term delivery groups. Med Biol Eng\n",
    "Comput 46, 911–922 (2008). https://doi.org/10.1007/s11517-008-0350-y\n",
    "\n",
    "[2] Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C.,\n",
    "Mark, R., … & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and\n",
    "PhysioNet: Components of a new research resource for complex physiologic\n",
    "signals. Circulation \\[Online\\]. 101 (23), pp. e215–e220."
   ],
   "id": "30eb2606-f45a-4730-9fe9-a340b2a1a4ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o ../term-preterm-ehg-database-1.0.1.zip https://physionet.org/static/published-projects/tpehgdb/term-preterm-ehg-database-1.0.1.zip\n",
    "!unzip ../term-preterm-ehg-database-1.0.1.zip -d ../"
   ],
   "id": "3a4755f0-bf34-4d91-8b92-1a88ee422c9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../individual_features\n",
    "!python3 ../EHG-Oversampling/experiments/all_features.py ../term-preterm-ehg-database-1.0.1/tpehgdb ../individual_features --study FeaturesKhan\n",
    "!python3 ../EHG-Oversampling/experiments/process_feature_files.py ../individual_features ../"
   ],
   "id": "9b1de863-c1fa-4b5d-830f-19eb045349e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the features\n",
    "\n",
    "In this section, we will load the dataset from the CSV files created in\n",
    "the previous step.\n",
    "\n",
    "We start by importing the required modules."
   ],
   "id": "a61520d2-3c59-44f1-88a7-6b3fbf35ac7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, make_scorer"
   ],
   "id": "2449347b-0d3a-47f8-b970-6ad49bc1905f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load feature matrix (features) and labels (y) from CSV files. The\n",
    "`head()` function displays the first few rows of each dataframe for a\n",
    "quick overview."
   ],
   "id": "16b573d3-e287-4bd7-a72c-85b419703e25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading feature vectors\n",
    "features=pd.read_csv(os.path.join('..','raw_features.csv'))\n",
    "features.head()"
   ],
   "id": "bd670cf2-c19b-4353-a10b-46ca6fa35242"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading labels\n",
    "y=pd.read_csv(os.path.join('..','target.csv'))\n",
    "y.head()"
   ],
   "id": "f7ce001c-534e-43e2-8553-9cffe0ebfc0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features required for our study\n",
    "khan_features = [\n",
    "    'FeaturesJager_fmed_ch1', 'FeaturesJager_max_lyap_ch1',\n",
    "    'FeaturesJager_sampen_ch1', 'FeaturesJager_fmed_ch2',\n",
    "    'FeaturesJager_max_lyap_ch2', 'FeaturesJager_sampen_ch2',\n",
    "    'FeaturesJager_fmed_ch3', 'FeaturesJager_max_lyap_ch3',\n",
    "    'FeaturesJager_sampen_ch3',\n",
    " ]\n",
    "generic_features=[ c for c in features.columns if 'FeaturesAcharya' in c and 'SampleEntropy' in c ]\n",
    "\n",
    "# Extract the relevant features for the study\n",
    "X = features[khan_features + generic_features]\n",
    "\n",
    "# Display summary information about the selected features\n",
    "X.info()"
   ],
   "id": "2330d84f-cb0f-418d-8f3a-29b782a3c388"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier Training and Evaluation without Data Leakage\n",
    "\n",
    "In this section, we will train and evaluate the SVM-FG model without the\n",
    "data leakage problem - i.e. with a correct evaluation on new EHG samples\n",
    "not used in training."
   ],
   "id": "397d7590-2cc0-49d9-8eb8-ae7586692a10"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do this in three parts:\n",
    "\n",
    "-   **Oversampling training and validation sets separately**: First, we\n",
    "    will do the oversampling inside our KFold CV loop - i.e. oversample\n",
    "    training data and validation data separately to get balanced classes\n",
    "    in each set. We will train the model on the training set and\n",
    "    evaluate on validation set. We will see that the accuracy due to\n",
    "    this procedure is somewhat less than in the earlier example, where\n",
    "    we oversampled before dividing into training and validation.\n",
    "\n",
    "-   **Oversampling training set and evaluating on unprocessed validation\n",
    "    set**: The approach above addresses the data leakage due to\n",
    "    oversampling on the entire data set together. However, it is still\n",
    "    not a realistic view of how our model will perform in real usage,\n",
    "    when the prevalence of pre-term birth is much less. In the next\n",
    "    part, we will evaluate our model using unprocessed (not oversampled)\n",
    "    validation set, to get a better estimate of its real performance.\n",
    "\n",
    "-   **Using pipelines**: When training a machine learning model with\n",
    "    preprocessing steps, it can be helpful to use a\n",
    "    [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "    to cross validate the model fitting and preprocessing together.\n",
    "    Since we use a preprocessing step from the `imbalanced-learn`\n",
    "    package, we use their\n",
    "    [Pipeline](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html)\n",
    "    implementation."
   ],
   "id": "fc065d2d-afdc-4f20-b0b1-8907d12ffdb2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling training and validation sets separately"
   ],
   "id": "1bb6afa7-527e-4d97-833f-626213616faa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.logspace(start=-5, stop=5, num=11, base=10)\n",
    "C_range = np.logspace(start=-5, stop=5, num=11, base=10)\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range}\n",
    "\n",
    "# Create SVC and GridSearchCV\n",
    "svc = SVC(kernel='rbf', random_state=15)\n",
    "clf = GridSearchCV(svc, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# Dictionary to store performance metrics\n",
    "metrics = {'accuracy': [], 'error': [], 'specificity': [], 'sensitivity': []}\n",
    "\n",
    "# Create figure to plot heatmaps\n",
    "fig, axes = plt.subplots(1, 5, figsize=(30, 12))\n",
    "\n",
    "oversampler = imblearn.over_sampling.ADASYN(n_neighbors=5, random_state=15)\n",
    "\n",
    "# Loop through the folds of the cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.to_numpy()[train_index], X.to_numpy()[test_index]\n",
    "    y_train, y_test = y.to_numpy()[train_index], y.to_numpy()[test_index]\n",
    "    \n",
    "    X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n",
    "    # Train the model on training set\n",
    "    clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "    # Plot the grid search results\n",
    "    scores = clf.cv_results_[\"mean_test_score\"].reshape(C_range.shape[0], gamma_range.shape[0])\n",
    "    im=axes[fold].imshow(scores, interpolation=\"nearest\", cmap=plt.cm.hot)\n",
    "    axes[fold].set_xlabel(\"gamma\")\n",
    "    axes[fold].set_ylabel(\"C\")\n",
    "    axes[fold].set_xticks(np.arange(gamma_range.shape[0]), labels=gamma_range, rotation=45)\n",
    "    axes[fold].set_yticks(np.arange(gamma_range.shape[0]), labels=C_range)\n",
    "    axes[fold].set_title(f\"Validation accuracy fold {fold + 1}\")\n",
    "\n",
    "    # Oversample test set\n",
    "    X_test_oversampled, y_test_oversampled = oversampler.fit_resample(X_test, y_test)\n",
    "    # Evaluate the model on the testing set\n",
    "    y_pred_oversampled = clf.predict(X_test_oversampled)\n",
    "    # Compute metrics\n",
    "    metrics['accuracy'].append(accuracy_score(y_test_oversampled, y_pred_oversampled))\n",
    "    metrics['error'].append(1 - accuracy_score(y_test_oversampled, y_pred_oversampled))\n",
    "    metrics['sensitivity'].append(recall_score(y_test_oversampled, y_pred_oversampled))\n",
    "    metrics['specificity'].append(recall_score(y_test_oversampled, y_pred_oversampled, pos_label=0))\n",
    "    \n",
    "fig.show()\n",
    "\n",
    "# Create a DataFrame from the performance metrics\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Average performance on the test set\n",
    "print(\"Performance on test set:\")\n",
    "print(metrics_df.mean())\n",
    "# Standard error of the performance metrics\n",
    "print(\"Standard error:\")\n",
    "print(metrics_df.std() / np.sqrt(kfold.get_n_splits()))"
   ],
   "id": "7df429c9-7334-4c6c-911a-16df2b6545c5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling training set and evaluating on unprocessed validation set"
   ],
   "id": "d337250f-9afc-4eac-b737-ba821e293958"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.logspace(start=-5, stop=5, num=11, base=10)\n",
    "C_range = np.logspace(start=-5, stop=5, num=11, base=10)\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range}\n",
    "\n",
    "# Create SVC and GridSearchCV\n",
    "svc = SVC(kernel='rbf', random_state=15)\n",
    "clf = GridSearchCV(svc, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# Dictionary to store performance metrics\n",
    "metrics = {'accuracy': [], 'error': [], 'specificity': [], 'sensitivity': []}\n",
    "\n",
    "# Create figure to plot heatmaps\n",
    "fig, axes = plt.subplots(1, 5, figsize=(30, 12))\n",
    "\n",
    "oversampler = imblearn.over_sampling.ADASYN(n_neighbors=5, random_state=15)\n",
    "\n",
    "# Loop through the folds of the cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.to_numpy()[train_index], X.to_numpy()[test_index]\n",
    "    y_train, y_test = y.to_numpy()[train_index], y.to_numpy()[test_index]\n",
    "    \n",
    "    X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n",
    "    # Train the model on training set\n",
    "    clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "    # Plot the grid search results\n",
    "    scores = clf.cv_results_[\"mean_test_score\"].reshape(C_range.shape[0], gamma_range.shape[0])\n",
    "    im=axes[fold].imshow(scores, interpolation=\"nearest\", cmap=plt.cm.hot)\n",
    "    axes[fold].set_xlabel(\"gamma\")\n",
    "    axes[fold].set_ylabel(\"C\")\n",
    "    axes[fold].set_xticks(np.arange(gamma_range.shape[0]), labels=gamma_range, rotation=45)\n",
    "    axes[fold].set_yticks(np.arange(gamma_range.shape[0]), labels=C_range)\n",
    "    axes[fold].set_title(f\"Validation accuracy fold {fold + 1}\")\n",
    "\n",
    "    # Evaluate the model on the testing set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Compute metrics\n",
    "    metrics['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    metrics['error'].append(1 - accuracy_score(y_test, y_pred))\n",
    "    metrics['sensitivity'].append(recall_score(y_test, y_pred))\n",
    "    metrics['specificity'].append(recall_score(y_test, y_pred, pos_label=0))\n",
    "    \n",
    "fig.show()\n",
    "\n",
    "# Create a DataFrame from the performance metrics\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Average performance on the test set\n",
    "print(\"Performance on test set:\")\n",
    "print(metrics_df.mean())\n",
    "# Standard error of the performance metrics\n",
    "print(\"Standard error:\")\n",
    "print(metrics_df.std() / np.sqrt(kfold.get_n_splits()))"
   ],
   "id": "95e7fc43-8d03-4d2f-9390-ef9cd5c5a9cb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pipelines"
   ],
   "id": "1518d4a1-6023-4676-91ad-4f798092e91a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define specificity and sensitivity scoring functions\n",
    "def specificity_score(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=0)\n",
    "def sensitivity_score(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred)\n",
    "\n",
    "# Create scorers using make_scorer\n",
    "specificity = make_scorer(specificity_score)\n",
    "sensitivity = make_scorer(sensitivity_score)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(30, 12))\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.logspace(start=-5, stop=5, num=11, base=10)\n",
    "C_range = np.logspace(start=-5, stop=5, num=11, base=10)\n",
    "parameters={'SVM__C': C_range, 'SVM__gamma': gamma_range}\n",
    "\n",
    "# Define scoring metrics for grid search\n",
    "scoring = {'accuracy':'accuracy','sensitivity':sensitivity,'specificity':specificity}\n",
    "\n",
    "# Define the pipeline\n",
    "model = imblearn.pipeline.Pipeline([\n",
    "        ('ADASYN', imblearn.over_sampling.ADASYN(random_state=5)),\n",
    "        ('SVM', SVC(kernel='rbf', random_state=5))\n",
    "    ])\n",
    "\n",
    "# Define GridSearchCV\n",
    "clf = GridSearchCV(model, parameters, cv=10, scoring=scoring, refit='accuracy')\n",
    "\n",
    "# Loop through the folds of the cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.to_numpy()[train_index], X.to_numpy()[test_index]\n",
    "    y_train, y_test = y.to_numpy()[train_index], y.to_numpy()[test_index]\n",
    "\n",
    "    # Perform grid search\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Plot the grid search results\n",
    "    scores = clf.cv_results_[\"mean_test_accuracy\"].reshape(C_range.shape[0], gamma_range.shape[0])\n",
    "    im=axes[fold].imshow(scores, interpolation=\"nearest\", cmap=plt.cm.hot)\n",
    "    axes[fold].set_xlabel(\"gamma\")\n",
    "    axes[fold].set_ylabel(\"C\")\n",
    "    axes[fold].set_xticks(np.arange(gamma_range.shape[0]), labels=gamma_range, rotation=45)\n",
    "    axes[fold].set_yticks(np.arange(gamma_range.shape[0]), labels=C_range)\n",
    "    axes[fold].set_title(f\"Validation accuracy fold {fold + 1}\")\n",
    "\n",
    "    # Evaluate the model on the testing set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Compute metrics\n",
    "    metrics['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    metrics['error'].append(1 - accuracy_score(y_test, y_pred))\n",
    "    metrics['sensitivity'].append(recall_score(y_test, y_pred))\n",
    "    metrics['specificity'].append(recall_score(y_test, y_pred, pos_label=0))\n",
    "    \n",
    "fig.show()\n",
    "\n",
    "# Create a DataFrame from the performance metrics\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Average performance on the test set\n",
    "print(\"Performance on test set:\")\n",
    "print(metrics_df.mean())\n",
    "# Standard error of the performance metrics\n",
    "print(\"Standard error:\")\n",
    "print(metrics_df.std() / np.sqrt(kfold.get_n_splits()))"
   ],
   "id": "7763682f-40e6-4465-a349-b8b259cc8d43"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "| Metric | Original | Reproduced With Data Leakage | Reproduced Without Data Leakage (Oversampled test set) | Reproduced Without Data Leakage (Unprocessed test set) | Reproduced Without Data Leakage (Using pipeline) |\n",
    "|:--------:|:-----:|:-----------------:|:-------------:|:----------:|:--------:|\n",
    "| Accuracy | 95.5 | 97.12 ± 0.74 | 49.71 ± 1.59 | 84.56 ± 1.62 | 85.91 ± 1.28 |\n",
    "| Error | 4.48 | 2.88 ± 0.74 | 50.29 ± 1.59 | 15.43 ± 1.62 | 14.09 ± 1.28 |\n",
    "| Specificity | 97.13 | 99.62 ± 0.38 | 2.99 ± 2.08 | 0.00 ± 0.00 | 0.00 ± 0.00 |\n",
    "| Sensitivity | 93.51 | 94.62 ± 1.41 | 96.92 ± 1.88 | 96.92 ± 1.88 | 98.46 ± 1.45 |"
   ],
   "id": "dbdf44e5-82d5-43eb-8b76-61dd71e18f5a"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
