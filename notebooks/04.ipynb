{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In\n",
    "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shaivimalik/medicine_preprocessing-on-entire-dataset/blob/main/notebooks/04.ipynb)"
   ],
   "id": "187c1659-8c47-4cac-97e9-c0b0d93791d5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the preceding notebooks, we demonstrated the impact of data leakage\n",
    "on a model’s performance on the test set and real-world data. In this\n",
    "notebook, we will reproduce the results published in **Characterization\n",
    "of Term and Preterm Deliveries using Electrohysterograms Signatures**[1]\n",
    "without the data leakage error. Our goal here is to demonstrate the\n",
    "correct way of preprocessing the dataset and discuss the changes in the\n",
    "reported metrics upon rectification of the error.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "-   Implement the described techniques and train SVM without data\n",
    "    leakage errors.\n",
    "-   Analyze and compare our results with those published in the paper\n",
    "    and obtained in the previous notebook.\n",
    "\n",
    "[1] M. U. Khan, S. Aziz, S. Ibraheem, A. Butt and H. Shahid,\n",
    "“Characterization of Term and Preterm Deliveries using\n",
    "Electrohysterograms Signatures,” 2019 IEEE 10th Annual Information\n",
    "Technology, Electronics and Mobile Communication Conference (IEMCON),\n",
    "Vancouver, BC, Canada, 2019, pp. 0899-0905, doi:\n",
    "10.1109/IEMCON.2019.893629"
   ],
   "id": "36a1c7c8-724a-4f68-9f21-f25544849575"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the data & Generate Features\n",
    "\n",
    "The **Term-Preterm EHG Database**[1] is a collection of EHG signals\n",
    "obtained from 1997 to 2005 at the University Medical Centre Ljubljana,\n",
    "Department of Obstetrics and Gynecology. Electrohysterograms signatures\n",
    "are obtained by placing four electrodes on the abdomen of the mother.\n",
    "The TPEGH DB consists of EHG records obtained from 262 women who had\n",
    "full-term pregnancies and 38 whose pregnancies ended prematurely. Each\n",
    "record is composed of three channels, recorded from 4 electrodes. The\n",
    "differences in the electrical potentials of the electrodes were\n",
    "recorded, producing 3 channels. Each record consists of two files, a\n",
    "header file (.hea) containing information regarding the record and the\n",
    "data file (.dat) containing signal data[2].\n",
    "\n",
    "We’ll begin by acquiring the TPEGH DB (Term-Preterm ElectroHysteroGram\n",
    "Database) and extracting relevant features for our model training. The\n",
    "following cell will:\n",
    "\n",
    "-   Clone the project repository\n",
    "-   Download the TPEGH DB dataset\n",
    "-   Install required dependencies\n",
    "\n",
    "Note that the download may take some time depending on your internet\n",
    "connection speed.\n",
    "\n",
    "[1] Fele-Žorž, G., Kavšek, G., Novak-Antolič, Ž. et al. A comparison of\n",
    "various linear and non-linear signal processing techniques to separate\n",
    "uterine EMG records of term and pre-term delivery groups. Med Biol Eng\n",
    "Comput 46, 911–922 (2008). https://doi.org/10.1007/s11517-008-0350-y\n",
    "\n",
    "[2] Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C.,\n",
    "Mark, R., … & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and\n",
    "PhysioNet: Components of a new research resource for complex physiologic\n",
    "signals. Circulation \\[Online\\]. 101 (23), pp. e215–e220."
   ],
   "id": "7f1840a1-e5c2-49ac-ad88-23a9713094a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/shaivimalik/medicine_preprocessing-on-entire-dataset.git\n",
    "%cd medicine_preprocessing-on-entire-dataset\n",
    "!pip install -r requirements.txt\n",
    "!curl -O https://physionet.org/static/published-projects/tpehgdb/term-preterm-ehg-database-1.0.1.zip\n",
    "!unzip term-preterm-ehg-database-1.0.1.zip"
   ],
   "id": "577f0756-eced-4861-aedc-833e2be6f0c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir individual_features\n",
    "!python3 EHG-Oversampling/experiments/all_features.py term-preterm-ehg-database-1.0.1/tpehgdb individual_features --study FeaturesKhan\n",
    "!python3 EHG-Oversampling/experiments/process_feature_files.py individual_features ./\n",
    "%cd notebooks"
   ],
   "id": "f32f215e-a844-405e-b146-04138483f23f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the features\n",
    "\n",
    "In this section, we will load the dataset from the CSV files created in\n",
    "the previous step.\n",
    "\n",
    "We start by importing the required modules."
   ],
   "id": "b4b0c3e2-d47d-43a9-ae7c-918133112d7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, make_scorer"
   ],
   "id": "7f46070c-e156-4b84-8039-c49cf352384f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load feature matrix (features) and labels (y) from CSV files. The\n",
    "`head()` function displays the first few rows of each dataframe for a\n",
    "quick overview."
   ],
   "id": "16cf15c0-1fc9-48f4-8d22-b0918120415d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading feature vectors\n",
    "features=pd.read_csv(os.path.join('..','raw_features.csv'))\n",
    "features.head()"
   ],
   "id": "63b8fec7-d842-4684-bbf8-1e0e9de6ad6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading labels\n",
    "y=pd.read_csv(os.path.join('..','target.csv'))\n",
    "y.head()"
   ],
   "id": "17e15b0d-1a33-47d6-9c71-e044cfa3e88b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features required for our study\n",
    "khan_features = [\n",
    "    'FeaturesJager_fmed_ch1', 'FeaturesJager_max_lyap_ch1',\n",
    "    'FeaturesJager_sampen_ch1', 'FeaturesJager_fmed_ch2',\n",
    "    'FeaturesJager_max_lyap_ch2', 'FeaturesJager_sampen_ch2',\n",
    "    'FeaturesJager_fmed_ch3', 'FeaturesJager_max_lyap_ch3',\n",
    "    'FeaturesJager_sampen_ch3',\n",
    " ]\n",
    "generic_features=[ c for c in features.columns if 'FeaturesAcharya' in c and 'SampleEntropy' in c ]\n",
    "\n",
    "# Extract the relevant features for the study\n",
    "X = features[khan_features + generic_features]\n",
    "\n",
    "# Display summary information about the selected features\n",
    "X.info()"
   ],
   "id": "0dd8c10c-e9a2-41b7-89c1-2efbc4fde048"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier Training and Evaluation without Data Leakage\n",
    "\n",
    "In this section, we will train and evaluate the SVM-FG model using\n",
    "10-fold cross validation. The paper doesn’t report the hyperparameters\n",
    "used to train the model. Therefore, we will use `GridSearchCV` to find\n",
    "optimal hyperparameter values for our classifier. We will then report\n",
    "the accuracy, error, sensitivity and specificity, along with the\n",
    "corresponding hyperparameter values.\n",
    "\n",
    "We begin by creating custom scoring functions for specificity and\n",
    "sensitivity. After that, we define the range of values for\n",
    "hyperparameters C and gamma. `GridSearchCV` will search within these\n",
    "ranges to find the optimal value of each hyperparameter."
   ],
   "id": "7c82b29a-2c69-4ea8-b21a-36dbbdb3a753"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define specificity and sensitivity scoring functions\n",
    "def specificity_score(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=0)\n",
    "def sensitivity_score(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred)\n",
    "\n",
    "# Create scorers using make_scorer\n",
    "specificity = make_scorer(specificity_score)\n",
    "sensitivity = make_scorer(sensitivity_score)\n",
    "\n",
    "# Define parameters\n",
    "gamma_range = np.logspace(start=-5, stop=5, num=11, base=2)\n",
    "C_range = np.logspace(start=-5, stop=5, num=11, base=10)\n",
    "parameters = {'C': C_range, 'gamma': gamma_range}\n",
    "\n",
    "# Define scoring metrics for grid search including accuracy, sensitivity, and specificity\n",
    "scoring = {'accuracy':'accuracy','sensitivity':sensitivity,'specificity':specificity}"
   ],
   "id": "dfd65b17-e21b-43c7-acb1-00a95987083f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Departing from the methodology followed in the paper, we will not\n",
    "oversample the entire dataset. Instead, we will use ADASYN[1] to\n",
    "oversample each training set separately during 10-fold cross-validation,\n",
    "leaving the test set unaltered. The `pipeline` in `imbalanced-learn`\n",
    "handles this for us and oversamples the training set correctly.\n",
    "\n",
    "[1] Haibo He, Yang Bai, E. A. Garcia and Shutao Li, “ADASYN: Adaptive\n",
    "synthetic sampling approach for imbalanced learning,” 2008 IEEE\n",
    "International Joint Conference on Neural Networks (IEEE World Congress\n",
    "on Computational Intelligence), Hong Kong, 2008, pp. 1322-1328, doi:\n",
    "10.1109/IJCNN.2008.4633969. keywords: {Classification\n",
    "algorithms;Decision trees;Algorithm design and analysis;Training\n",
    "data;Machine learning;Accuracy;Machine learning algorithms}"
   ],
   "id": "01541da8-6215-4db7-bde3-df1648535fa7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "model = imblearn.pipeline.Pipeline([\n",
    "        ('ADASYN', imblearn.over_sampling.ADASYN(random_state=5)),\n",
    "        ('SVM', SVC(kernel='rbf', random_state=5))\n",
    "    ])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "parameters={'SVM__C': C_range, 'SVM__gamma': gamma_range}\n",
    "\n",
    "# Define GridSearchCV with custom scorers\n",
    "clf = GridSearchCV(model, parameters, cv=10, scoring=scoring, refit='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "clf.fit(X.to_numpy(), y.to_numpy())\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", clf.best_score_)\n",
    "print(\"Error:\", (1-clf.best_score_))\n",
    "print(\"Sensitivity:\", clf.cv_results_['mean_test_sensitivity'][clf_cor.best_index_])\n",
    "print(\"Specificity:\", clf.cv_results_['mean_test_specificity'][clf_cor.best_index_])\n",
    "print(\"Best hyperparameters:\", clf.best_params_)"
   ],
   "id": "74494f95-641d-4d34-95b6-983be5d88d75"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code cell creates a heatmap to visualise the performance of the SVM\n",
    "model. It plots the mean test accuracy obtained for different\n",
    "combinations of hyperparamters C and gamma during `GridSearchCV`. The\n",
    "x-axis represents different gamma values, and the y-axis represents\n",
    "different C values. The colorbar on the side provides a scale for\n",
    "interpreting the scores."
   ],
   "id": "e7aaa879-07e4-45ca-b472-e19dab561402"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Reshape the mean test accuracy scores into a 2D array\n",
    "scores = clf.cv_results_[\"mean_test_accuracy\"].reshape(len(C_range), len(gamma_range))\n",
    "# Display the scores as a heatmap\n",
    "plt.imshow(scores, interpolation=\"nearest\", cmap=plt.cm.hot)\n",
    "# Set the x-axis label\n",
    "plt.xlabel(\"gamma\")\n",
    "# Set the y-axis label\n",
    "plt.ylabel(\"C\")\n",
    "# Display the colorbar\n",
    "plt.colorbar()\n",
    "# Set the x-axis ticks and labels\n",
    "plt.xticks(np.arange(gamma_range.shape[0]), labels=gamma_range, rotation=45)\n",
    "# Set the y-axis ticks and labels\n",
    "plt.yticks(np.arange(gamma_range.shape[0]), labels=C_range)\n",
    "# Set the title of the plot\n",
    "plt.title(\"Validation accuracy\")\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "afbacbeb-e45e-44a3-b252-602bd7ca67db"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "It is evident from the results that the model trained with data leakage\n",
    "has achieved higher accuracy than the model trained without data\n",
    "leakage. This verifies that data leakage leads to overly optimistic\n",
    "estimates of model performance. However, it’s important to note that in\n",
    "the model without data leakage, the test set distribution may be more\n",
    "imbalanced, with a higher proportion of majority class samples. This\n",
    "imbalance can boost the model’s performance, as it allows the model to\n",
    "perform well on the majority class.\n",
    "\n",
    "However, despite this advantage, the model without data leakage still\n",
    "underperforms compared to the model with data leakage. This\n",
    "underperformance highlights the significant impact of data leakage in\n",
    "inflating model performance. If we were to oversample the test set to\n",
    "balance the classes for a fairer comparison, the accuracy of the model\n",
    "without data leakage would likely decrease, as the increased\n",
    "representation of the minority class would present a more challenging\n",
    "scenario. Consequently, the gap between the accuracy reported in our\n",
    "results and the published accuracy would widen even further. Thus, the\n",
    "observed ~10% increase in accuracy can be considered as the lower limit\n",
    "of the performance enhancement produced by data leakage in this case.\n",
    "\n",
    "| Metric | Original | Reproduced With Data Leakage | Reproduced Without Data Leakage |\n",
    "|:-----------:|:-------:|:-----------------------:|:------------------------:|\n",
    "| Accuracy | 95.5 | 99.81 | 87.26 |\n",
    "| Error | 4.48 | 0.19 | 12.74 |\n",
    "| Specificity | 97.13 | 99.62 | 0.0 |\n",
    "| Sensitivity | 93.51 | 100.0 | 100.0 |\n",
    "\n",
    "In conclusion, we should always split our dataset prior to\n",
    "preprocessing. This ensures integrity and reproducibility of our\n",
    "results."
   ],
   "id": "ee78c303-5bcc-4988-879d-ad7888d57b87"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
